#!/usr/bin/env bash
# File: distributed_crawler/tests/test_all_features.sh
# Purpose: End-to-end validation of Master-Node features.
# Usage: cd Distributed-Web-Crawling/distributed_crawler/tests
#        ./test_all_features.sh

set -euo pipefail
trap 'echo "ðŸ§¹ Cleaning upâ€¦"; kill "$MON_PID" >/dev/null 2>&1 || true; \
     sudo iptables -D OUTPUT -p tcp -d $ES_IP --dport $ES_PORT -j DROP >/dev/null 2>&1 || true' EXIT

# â”€â”€ Derive paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
BASE_DIR="$(dirname "$SCRIPT_DIR")"            # .../distributed_crawler
MASTER_NODE_PY="$BASE_DIR/master_node.py"      # path to master_node.py
TASKS_DIR="$BASE_DIR"                          # tasks.py lives here
MONITOR_LOG="$SCRIPT_DIR/monitor.log"
# â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INDEXER_API_BASE="http://10.128.0.5:8000/api"
ES_IP="10.128.0.5"
ES_PORT=9200
MONGO_CMD="mongo --quiet"
DB="Crawler"
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

echo "ðŸ”¹ 1) Starting heartbeat & timeout monitors (5s interval)â€¦"
# spawn inline python monitors, redirect output to a log in this tests dir
nohup python3 <<'PYCODE' > "$MONITOR_LOG" 2>&1 &
import threading, time, sys
sys.path.insert(0, "")
from master_node import heartbeat_monitor, monitor_tasks
t1 = threading.Thread(target=heartbeat_monitor, kwargs={'interval':5}, daemon=True)
t2 = threading.Thread(target=monitor_tasks,  kwargs={'interval':5}, daemon=True)
t1.start(); t2.start()
time.sleep(300)
PYCODE
MON_PID=$!
echo "    â†’ MON_PID=$MON_PID"
sleep 7

echo
echo "ðŸ”¹ 2) Testing CLI search modesâ€¦"
for MODE in match boolean phrase; do
  echo -n "   â€¢ $MODE â†’ "
  python3 "$MASTER_NODE_PY" search -k "example" -m "$MODE" -n 2
done

echo
echo "ðŸ”¹ 3) Testing CLI status (crawler & indexer heartbeat)â€¦"
STATUS=$(python3 "$MASTER_NODE_PY" status)
echo "$STATUS"
echo "$STATUS" | grep -qE "Active crawlers: [1-9]" && echo "    âœ“ Crawlers OK" || { echo "    âœ— Crawlers FAIL"; exit 1; }
echo "$STATUS" | grep -q "Indexer active: True"    && echo "    âœ“ Indexer OK"  || { echo "    âœ— Indexer FAIL";  exit 1; }

echo
echo "ðŸ”¹ 4) Testing Indexer API endpointsâ€¦"
for MODE in match boolean phrase; do
  HTTP=$(curl -s -o /dev/null -w "%{http_code}" \
    "${INDEXER_API_BASE}/search?query=example&mode=${MODE}")
  echo -n "   â€¢ /search?mode=$MODE â†’ $HTTP   "
  [ "$HTTP" = "200" ] && echo "âœ“" || { echo "âœ—"; exit 1; }
done
HTTP=$(curl -s -o /dev/null -w "%{http_code}" "${INDEXER_API_BASE}/metrics")
echo -n "   â€¢ /metrics â†’ $HTTP   "
[ "$HTTP" = "200" ] && echo "âœ“" || { echo "âœ—"; exit 1; }

echo
echo "ðŸ”¹ 5) Testing fault-tolerant indexing retryâ€¦"
cd "$TASKS_DIR"
python3 <<'PYCODE'
import time, sys
sys.path.insert(0, "")
from tasks import index_document
res = index_document.apply_async(args=("test-doc", {"url":"x","text":"y"}))
time.sleep(5)
print("    â€¢ state =", res.state)
PYCODE

echo
echo "ðŸ”¹ 6) Simulating ES DOWN (block via iptables)â€¦"
sudo iptables -I OUTPUT -p tcp -d "$ES_IP" --dport "$ES_PORT" -j DROP
sleep 7
DOWN=$(python3 "$MASTER_NODE_PY" status)
echo "$DOWN"
echo "$DOWN" | grep -q "Indexer active: False" && echo "    âœ“ DOWN detected" || { echo "    âœ— DOWN not detected"; exit 1; }

echo "ðŸ”¹ Restoring ES accessâ€¦"
sudo iptables -D OUTPUT -p tcp -d "$ES_IP" --dport "$ES_PORT" -j DROP
sleep 7
UP=$(python3 "$MASTER_NODE_PY" status)
echo "$UP"
echo "$UP" | grep -q "Indexer active: True" && echo "    âœ“ UP detected" || { echo "    âœ— UP not detected"; exit 1; }

echo
echo "ðŸ”¹ 7) Testing stale-task timeout & requeueâ€¦"
$MONGO_CMD <<EOF
use $DB
db.task_status.insertOne({
  task_id: "stale-test",
  url: "http://example.com",
  depth: 1,
  politeness: 0.5,
  status: "queued",
  created_at: 0
});
EOF
sleep 12
COUNT=$($MONGO_CMD <<EOF
use $DB
db.task_status.count({ origin: "stale-test" })
EOF
)
[ "$COUNT" -ge 1 ] && echo "    âœ“ requeued ($COUNT copies)" || { echo "    âœ— not requeued"; exit 1; }

echo
echo "âœ… ALL TESTS PASSED! ðŸŽ‰"

